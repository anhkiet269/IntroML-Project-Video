{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPADjizRoZBP1u0qeQM7TMZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **NHẬP MÔN HỌC MÁY**\n","## THÔNG TIN NHÓM:\n","- 20120547: VÕ THÀNH PHONG\n","- 20120578: PHẠM QUỐC THÁI\n","- 20120125: BÙI ANH KIỆT\n","- 20120109: TRƯƠNG NGỌC HUY\n","- 20120166: NGUYỄN DƯƠNG TUẤN PHƯƠNG\n","\n","# LIÊN HỆ TÁC GIẢ COLAB:\n","- Email: 20120547@student.hcmus.edu.vn"],"metadata":{"id":"ljdPls4CZ_Ir"}},{"cell_type":"markdown","source":["# **TRIỂN KHAI KIẾN TRÚC MẠNG RESNET CHO TÁC VỤ NHẬN DẠNG ẢNH TRÊN BỘ DỮ LIỆU CIFAR-10**"],"metadata":{"id":"wEpcZqEUbPDe"}},{"cell_type":"markdown","source":["**LƯU Ý QUAN TRỌNG: Các thư mục cũng như file được tạo ra trong quá trình chạy file colab này đều là local, do đó muốn tải các thư mục, file về máy hãy chọn icon folder bên thanh menu bên trái và tải về trước khi tắt file colab đi.**\n"],"metadata":{"id":"_2qp7UfppJAA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8hBY1cjZkDW"},"outputs":[],"source":["#Import needed libaries\n","\n","#libaries for building model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","#libaries for training model\n","import torch\n","import ssl\n","import os\n","import argparse\n","import torchvision.transforms as T\n","import numpy as np\n","from torchvision.datasets.cifar import CIFAR10\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","from tqdm import tqdm\n","\n","#libaries for ploting results\n","import os\n","import numpy as np\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","source":["# 1. BUILDING MODEL"],"metadata":{"id":"GdpvIxDFdmJd"}},{"cell_type":"markdown","source":["Xây dựng PLainNet và ResNet với kiến trúc tổng quát như sau:\n","\n","!['image'](https://res.cloudinary.com/vtphong/image/upload/v1683601236/Intro2ML/Screenshot_2023-05-09_095922.png)"],"metadata":{"id":"Gz3PK1cmcUH2"}},{"cell_type":"code","source":["def init_weights(m):\n","    #Function to initial model'weights\n","    def f1(module):\n","        if isinstance(module, nn.Conv2d):\n","            torch.nn.init.kaiming_normal_(module.weight.data, nonlinearity='relu')\n","\n","    def f2(module):\n","        if isinstance(module, DoubleConvBlock):\n","            ds = module.conv_downsample\n","            if ds:\n","                ds.weight.data.fill_(1 / module.in_channels)\n","                ds.bias.data.fill_(0)\n","\n","    m.apply(f1)         \n","    m.apply(f2)"],"metadata":{"id":"QAR5wlNHcNkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Footer(nn.Module):\n","    #This is the class that represents the last layers in the structure\n","    #including average pooling layer and fully connected layer\n","    def __init__(self, in_channels, in_size, out_labels):\n","        super().__init__()\n","        self.in_channels = in_channels\n","        self.in_size = in_size\n","        self.model = nn.Sequential(\n","            nn.AvgPool2d(in_size),\n","            nn.Flatten(start_dim=1),\n","            nn.Linear(in_channels, out_labels)\n","        )\n","\n","    def forward(self, x):\n","        if x.shape[2] != self.in_size or x.shape[3] != self.in_size:\n","            raise ValueError(f'Expected input shape (*, {self.in_channels}, {self.in_size}, {self.in_size}), '\n","                             f'got {tuple(x.shape)}')\n","        return self.model.forward(x)"],"metadata":{"id":"78r4QFXPdstB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Trong bài báo, khi tác giả thực hiện đánh giá trên bộ Cifar-10 thì trong khối 6n convolutional layers sẽ chia nhỏ theo từng nhóm 2n layers với số lượng bộ lọc khác nhau.\n","\n","Do đó ta sẽ xây dựng một class DoubleConvBlock để thiết kế khối nhỏ gồm 2 lớp tích chập để tiện cho việc xây dựng 2n layers khác nhau chỉ ở số bộ lọc được sử dụng"],"metadata":{"id":"KqOjn-Pmesu4"}},{"cell_type":"code","source":["class DoubleConvBlock(nn.Module):\n","    def __init__(self, in_channels, in_size, shortcut=True, down_sample=False, option=None):\n","        super().__init__()\n","\n","        \"\"\"\n","        Padding is calculated as follows:\n","            (IN_DIM - F + 2P) / S + 1 = OUT_DIM\n","        F = filter size\n","        P = padding\n","        S = stride\n","        \"\"\"\n","\n","        assert option in {None, 'A', 'B'}, f\"'{option}' is an invalid option\"\n","        self.in_channels = in_channels\n","        self.in_size = in_size\n","        self.down_sample = down_sample\n","        self.shortcut = shortcut\n","        self.option = option\n","        self.conv_downsample = None\n","        if self.down_sample:\n","            if shortcut:\n","                assert option is not None, 'Must specify either option A or B when ' \\\n","                                           'downsampling with a residual shortcut'\n","            out_channels = in_channels * 2\n","            self.model = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1),\n","                nn.BatchNorm2d(out_channels),\n","                nn.ReLU(),\n","                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","            self.conv_downsample = nn.Conv2d(in_channels, out_channels, 1, stride=2)\n","        else:\n","            self.model = nn.Sequential(\n","                nn.Conv2d(in_channels, in_channels, 3, padding=1),\n","                nn.BatchNorm2d(in_channels),\n","                nn.ReLU(),\n","                nn.Conv2d(in_channels, in_channels, 3, padding=1),\n","                nn.BatchNorm2d(in_channels)\n","            )\n","    def forward(self, x):\n","        if not self.shortcut:               # No residual\n","            result = self.model.forward(x)\n","        elif not self.down_sample:          # Simple residual\n","            result = self.model.forward(x) + x\n","        elif self.option == 'A':            # Zero padding\n","            y = self.model.forward(x)\n","            x = F.max_pool2d(x, 1, 2)\n","            padded = torch.cat((x, torch.zeros_like(x)), dim=1)\n","            result = y + padded\n","        else:                               # Linear projection\n","            result = self.model.forward(x) + self.conv_downsample.forward(x)\n","        return F.relu(result)"],"metadata":{"id":"2mVigypfea__"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Xây dựng class CifarResNet**"],"metadata":{"id":"jDGvA0WEfqz0"}},{"cell_type":"code","source":["def common_str(obj):\n","    strings = [\n","        obj.__class__.__name__,\n","        str(obj.locals['n']),\n","        'R' if obj.locals['residual'] else 'P'\n","    ]\n","    option = obj.locals['option']\n","    if option is not None:\n","        strings.append(option)\n","    return '-'.join(strings)\n","\n","\n","class CifarResNet(nn.Module):\n","    def __init__(self, n, residual=True, option=None):\n","        self.locals = locals()\n","        super().__init__()\n","\n","        num_layers = {20, 32, 44, 56, 110}\n","        assert n in num_layers, f'N must be in {list(sorted(num_layers))}'\n","        k = (n - 2) // 6\n","\n","        modules = [nn.Conv2d(3, 16, 3, padding=1)]\n","        modules += [DoubleConvBlock(16, 32, shortcut=residual) for _ in range(k)]\n","\n","        modules.append(DoubleConvBlock(16, 32, shortcut=residual, down_sample=True, option=option))\n","        modules += [DoubleConvBlock(32, 16, shortcut=residual) for _ in range(k - 1)]\n","\n","        modules.append(DoubleConvBlock(32, 16, shortcut=residual, down_sample=True, option=option))\n","        modules += [DoubleConvBlock(64, 8, shortcut=residual) for _ in range(k - 1)]\n","\n","        modules.append(Footer(64, 8, 10))\n","        self.model = nn.Sequential(*modules)\n","        init_weights(self)\n","\n","    def forward(self, x):\n","        return self.model.forward(x)\n","\n","    @staticmethod\n","    def transform(x):\n","        return x - torch.mean(x, (1, 2), keepdim=True)\n","\n","    def __str__(self):\n","        return common_str(self)"],"metadata":{"id":"OWq_Z4EMfoh1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. TRAINING MODEL"],"metadata":{"id":"g9yPf_M_f2ua"}},{"cell_type":"code","source":["def create_component(large, n, residual, option):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    writer = SummaryWriter()\n","    now = datetime.now()\n","\n","    model = CifarResNet(n, residual, option).to(device)\n","    loss_function = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(\n","        model.parameters(),\n","        lr=0.01 if large else 0.1,\n","        weight_decay=0.0001,\n","        momentum=0.9\n","    )\n","    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n","        optimizer,\n","        milestones=(32_000, 48_000),\n","        gamma=0.1                       \n","    )\n","    return device, writer, now, model, loss_function, optimizer, scheduler"],"metadata":{"id":"5bxc0TkVT1h7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_data_loader(train_set, test_set, batch_size):\n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_set, batch_size=batch_size)\n","    return train_loader, test_loader"],"metadata":{"id":"8xJx1mCTVxpU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(n, residual, option):\n","    #Create components\n","    large = n >= 56\n","    device, writer, now, model, loss_function, optimizer, scheduler=create_component(large, n, residual, option)\n","    ssl._create_default_https_context = ssl._create_unverified_context      # Patch expired certificate error\n","    \n","    #Create dataset\n","    train_set = CIFAR10(\n","        root='data', train=True, download=True,\n","        transform=T.Compose([\n","            T.ToTensor(),\n","            model.transform,\n","            T.RandomCrop(32, padding=4)         # Pad each side by 4 pixels and randomly sample 32x32 image\n","        ])\n","    )\n","    test_set = CIFAR10(\n","        root='data', train=False,\n","        transform=T.Compose([\n","            T.ToTensor(),\n","            model.transform\n","        ])\n","    )\n","    train_loader, test_loader=create_data_loader(train_set, test_set, 128)\n","\n","    #Save traning results\n","    # Create folders\n","    root = os.path.join(\n","        'models',\n","        str(model),\n","    )\n","    weight_dir = os.path.join(root, 'weights')\n","    if not os.path.isdir(weight_dir):\n","        os.makedirs(weight_dir)\n","        \n","    train_losses = np.empty((2, 0))\n","    test_losses = np.empty((2, 0))\n","    train_errors = np.empty((2, 0))\n","    test_errors = np.empty((2, 0))\n","\n","    def save_metrics():\n","        np.save(os.path.join(root, 'train_losses'), train_losses)\n","        np.save(os.path.join(root, 'test_losses'), test_losses)\n","        np.save(os.path.join(root, 'train_errors'), train_errors)\n","        np.save(os.path.join(root, 'test_errors'), test_errors)\n","\n","    #Training model\n","    for epoch in range(1,161):\n","        if large and epoch == 1:        # Set learning rate back to 0.1 after warming up training\n","            for g in optimizer.param_groups:\n","                g['lr'] = 0.1\n","\n","        train_loss = 0\n","        accuracy = 0\n","        for data, labels in train_loader:\n","            data = data.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            predictions = model.forward(data)\n","            loss = loss_function(predictions, labels)\n","            loss.backward()\n","            optimizer.step()\n","            scheduler.step()        # Step scheduler every iteration, not epoch\n","\n","            train_loss += loss.item() / len(train_loader)\n","            accuracy += labels.eq(torch.argmax(predictions, 1)).sum().item() / len(train_set)\n","            del data, labels\n","        train_losses = np.append(train_losses, [[epoch], [train_loss]], axis=1)\n","        train_errors = np.append(train_errors, [[epoch], [1 - accuracy]], axis=1)\n","        writer.add_scalar('Loss/train', train_loss, epoch)\n","        writer.add_scalar('Error/train', 1 - accuracy, epoch)\n","\n","        if epoch % 4 == 0:\n","            with torch.no_grad():\n","                test_loss = 0\n","                accuracy = 0\n","                for data, labels in test_loader:\n","                    data = data.to(device)\n","                    labels = labels.to(device)\n","\n","                    predictions = model.forward(data)\n","                    loss = loss_function(predictions, labels)\n","\n","                    test_loss += loss.item() / len(test_loader)\n","                    accuracy += labels.eq(torch.argmax(predictions, 1)).sum().item() / len(test_set)\n","                    del data, labels\n","            test_losses = np.append(test_losses, [[epoch], [test_loss]], axis=1)\n","            test_errors = np.append(test_errors, [[epoch], [1 - accuracy]], axis=1)\n","            writer.add_scalar('Loss/test', test_loss, epoch)\n","            writer.add_scalar('Error/test', 1 - accuracy, epoch)\n","\n","            save_metrics()\n","            if epoch % 20 == 0:\n","                torch.save(model.state_dict(), os.path.join(weight_dir, f'cp_{epoch}'))\n","        if epoch%40==0:\n","            print('Epoch '+str(epoch)+' complete')\n","\n","    save_metrics()\n","    torch.save(model.state_dict(), os.path.join(weight_dir, 'final'))"],"metadata":{"id":"IQJZO3OpRwqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ns=[20, 32, 44, 56, 110]\n","residuals=[False, True]\n","option='A'"],"metadata":{"id":"W_VdbXV2vlDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for residual in residuals:\n","    if residual:\n","        for n in ns:\n","            train(n,residual,option)\n","    else:\n","        for n in ns:\n","            train(n, residual, None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALqDMSWrYjXx","outputId":"6b3b5139-a56d-4ee4-e606-68ef62e8f73a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 43391160.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-10-python.tar.gz to data\n","Epoch 40 complete\n","Epoch 80 complete\n","Epoch 120 complete\n","Files already downloaded and verified\n","Epoch 40 complete\n","Epoch 80 complete\n","Epoch 120 complete\n","Files already downloaded and verified\n","Epoch 40 complete\n","Epoch 80 complete\n","Epoch 120 complete\n","Files already downloaded and verified\n","Epoch 40 complete\n","Epoch 80 complete\n","Epoch 120 complete\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["# 3. PLOTING RESULTS"],"metadata":{"id":"X0ohb-o0njOX"}},{"cell_type":"code","source":["ROOT = 'results'\n","DPI = 300\n","\n","\n","def save(fig, path):\n","    fig.savefig(os.path.join(ROOT, path), dpi=DPI)\n","\n","\n","def plot(graph, info):\n","    for path, label, color in info:\n","        test_errors = np.load(os.path.join(path, 'test_errors.npy'))\n","        train_errors = np.load(os.path.join(path, 'train_errors.npy'))\n","        graph.plot(test_errors[0], test_errors[1] * 100, label=label, color=color)\n","        graph.plot(train_errors[0], train_errors[1] * 100, color=color, alpha=0.2)\n","    graph.legend()\n","\n","\n","def format_plot(graph):\n","    graph.set_ylabel('Error (%)')\n","    graph.set_ylim(0, 30)\n","    graph.set_xlabel('Epoch')\n","    graph.set_xlim(0, 160)\n","    graph.spines['top'].set_visible(False)\n","    graph.spines['right'].set_visible(False)"],"metadata":{"id":"KI2G2d5_nivY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plain_res_error_plotting():\n","    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n","    for p in axs:\n","        format_plot(p)\n","    plain, residual = axs\n","\n","    sizes = (20, 32, 44, 56)\n","    colors = ('orange', 'blue', 'red', 'green','black')\n","    plain_paths = (\n","        'models/CifarResNet-20-P',\n","        'models/CifarResNet-32-P',\n","        'models/CifarResNet-44-P',\n","        'models/CifarResNet-56-P',\n","        'models/CifarResNet-110-P'\n","    )\n","    plot(plain, zip(plain_paths, [f'Plain-{x}' for x in sizes], colors))\n","\n","    residual_paths = (\n","        'models/CifarResNet-20-R-A',\n","        'models/CifarResNet-32-R-A',\n","        'models/CifarResNet-44-R-A',\n","        'models/CifarResNet-56-R-A',\n","        'models/CifarResNet-110-R-A'\n","    )\n","    plot(residual, zip(residual_paths, [f'Residual-{x}' for x in sizes], colors))\n","\n","    fig.tight_layout()\n","    save(fig, 'plain_res_error')\n","    plt.show()\n","\n","\n","if __name__ == '__main__':\n","    plain_res_error_plotting()"],"metadata":{"id":"CatDXOeeoKTm"},"execution_count":null,"outputs":[]}]}